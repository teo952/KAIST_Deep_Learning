# -*- coding: utf-8 -*-
"""5차시_임준성.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qZk5-aHizGKv53nyvD5h2Z6t49U6lqLY
"""

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from sklearn.metrics import average_precision_score
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

!pip install gdown
!gdown https://drive.google.com/uc?id=1ZVCQoVuJwLdWSa0ecbECh9CmFNkO0DmE -O model_contrast.pth

# CIFAR-100 데이터셋 로드 및 전처리
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])
])

# 테스트 데이터셋
test_dataset = torchvision.datasets.CIFAR100(root='CIFAR100_Dataset', train=False, download=True, transform=transform)

# 테스트 데이터로더
test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)

print('데이터셋 및 데이터 로더의 준비가 완료되었습니다!')

# 특징 추출을 위한 ResNet18 딥러닝 네트워크
class ResNet18FeatureExtractor(nn.Module):
    def __init__(self):
        super(ResNet18FeatureExtractor, self).__init__()
        resnet = torchvision.models.resnet18(pretrained=True)
        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1])  # Fully Connected Layer 제거

    def forward(self, x):
        x = self.feature_extractor(x)
        return x.view(x.size(0), -1)  # Flatten to [batch_size, feature_dim]

# 연산 장치 설정 (GPU가 사용가능 하면 GPU사용)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 이미지 특징 추출을 위한 ResNet18 딥러닝 네트워크 선언
model_original = ResNet18FeatureExtractor() # 대조 학습을 적용하지 않은 원래 네트워크
model_contrast = ResNet18FeatureExtractor() # 대조 학습을 적용한 새로운 네트워크

# 대조 학습된 모델 불러오기
model_contrast.load_state_dict(torch.load('/content/model_contrast.pth'))

# 두 딥러닝 네트워크를 연산장치로 보냄
model_original = model_original.to(device)
model_contrast = model_contrast.to(device)

# 모델 평가모드
model_original.eval()
model_contrast.eval()

# 데이터 로더로 부터 나온 이미지 특징 추출하는 함수
def extract_features(model, dataloader):  # model: 딥러닝 네트워크, dataloader: 데이터로더
    features = []
    labels = []
    with torch.no_grad():
        for inputs, targets in tqdm(dataloader, desc="Extracting Features"):
            inputs = inputs.to(device)
            outputs = model(inputs)  # Feature extraction
            features.append(outputs.cpu().numpy())
            labels.append(targets.cpu().numpy())
    return np.concatenate(features), np.concatenate(labels)

features_original, labels_original = extract_features(model_original, test_dataloader)
features_contrast, labels_contrast = extract_features(model_contrast, test_dataloader)

print('\n\n 각 딥러닝 네트워크들을 사용해 특징 추출이 완료됐습니다!')

def show_feature(features, labels, title):
    # 특징 정규화
    features = features / np.linalg.norm(features, axis = 1)[:, None]

    # PCA 적용하여 2차원으로 축소
    pca = PCA(n_components=2)
    pca_result = pca.fit_transform(features)

    # 라벨별로 시각화
    label_range = np.array([33, 37, 66])  # 사용할 라벨 지정

    for label in label_range:
        idxs = labels == label
        plt.scatter(pca_result[idxs, 0], pca_result[idxs, 1], label=f'Label {label} ({test_dataset.classes[label]})', alpha=0.7)

    plt.title(title)
    plt.xlabel('PCA Component 1')
    plt.ylabel('PCA Component 2')
    plt.legend()
    plt.grid(True)
    plt.show()

# 시각화 실행
show_feature(features_original, labels_original, 'Feature space before contrastive learning')
show_feature(features_contrast, labels_contrast, 'Feature space after contrastive learning')